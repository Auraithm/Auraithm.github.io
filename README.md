<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Aha - A High-Performance and Efficient Diffusion Language Model - Ying Zhu, Jiaxin Wan, Tianyi Liang, Xu Guo, Xiaoran Liu, Zengfeng Huang, Ziwei He, Xipeng Qiu">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Ying Zhu, Jiaxin Wan, Tianyi Liang, Xu Guo, Xiaoran Liu, Zengfeng Huang, Ziwei He, Xipeng Qiu">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="Aha - A High-Performance and Efficient Diffusion Language Model">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Ying Zhu">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="Aha - A High-Performance and Efficient Diffusion Language Model">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Aha - A High-Performance and Efficient Diffusion Language Model">
  <meta name="citation_author" content="Zhu, Ying">
  <meta name="citation_author" content="Wan, Jiaxin">
  <meta name="citation_author" content="Liang, Tianyi">
  <meta name="citation_author" content="Guo, Xu">
  <meta name="citation_author" content="Liu, Xiaoran">
  <meta name="citation_author" content="Huang, Zengfeng">
  <meta name="citation_author" content="He, Ziwei">
  <meta name="citation_author" content="Qiu, Xipeng">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Aha - A High-Performance and Efficient Diffusion Language Model - Ying Zhu et al. | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- KaTeX for math rendering -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Aha - A High-Performance and Efficient Diffusion Language Model",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "Ying Zhu",
        "affiliation": {
          "@type": "Organization",
          "name": "Fudan University, Shanghai Innovation Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Jiaxin Wan",
        "affiliation": {
          "@type": "Organization",
          "name": "University of Electronic Science and Technology of China, Shanghai Innovation Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Tianyi Liang",
        "affiliation": {
          "@type": "Organization",
          "name": "East China Normal University, Shanghai Innovation Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Xu Guo",
        "affiliation": {
          "@type": "Organization",
          "name": "Fudan University, Shanghai Innovation Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Xiaoran Liu",
        "affiliation": {
          "@type": "Organization",
          "name": "Fudan University, Shanghai Innovation Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Zengfeng Huang",
        "affiliation": {
          "@type": "Organization",
          "name": "Fudan University, Shanghai Innovation Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Ziwei He",
        "affiliation": {
          "@type": "Organization",
          "name": "Shanghai Innovation Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Xipeng Qiu",
        "affiliation": {
          "@type": "Organization",
          "name": "Fudan University, Shanghai Innovation Institute"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Aha: A High-Performance and Efficient Diffusion Language Model</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="#" target="_blank">Ying Zhu</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Jiaxin Wan</a><sup>3,2</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Tianyi Liang</a><sup>4,2</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Xu Guo</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Xiaoran Liu</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Zengfeng Huang</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Ziwei He</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Xipeng Qiu</a><sup>1,2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block"><sup>1</sup>Fudan University, <sup>2</sup>Shanghai Innovation Institute,<br><sup>3</sup>University of Electronic Science and Technology of China, <br><sup>4</sup>East China Normal University<br><br>Conference name and year</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- GitHub Link -->
                      <span class="link-block">
                        <a href="https://github.com/YOUR_REPO_HERE" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="GitHub" style="width: 1.2em; height: 1.2em; vertical-align: middle; filter: invert(1);">
                        </span>
                        <span>GitHub</span>
                      </a>
                    </span>

                    <!-- Hugging Face Link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/YOUR_MODEL_HERE" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <img src="https://huggingface.co/front/assets/huggingface_logo.svg" alt="Hugging Face" style="width: 1.2em; height: 1.2em; vertical-align: middle;">
                      </span>
                      <span>Hugging Face</span>
                    </a>
                  </span>

                  <!-- Paper Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/YOUR_PAPER_ID.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Main Teaser Image -->
      <figure class="image">
        <img src="static/images/accuracy.png" alt="Aha Framework Overview" style="width: 100%; border-radius: 12px; box-shadow: 0 8px 16px rgba(0,0,0,0.15);"/>
      </figure>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- TL;DR -->
<section class="hero is-small is-light"  style="padding: 8rem 5rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;">TL;DR</h2>
        <div class="content has-text-left" style="font-size: 1.2rem; font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; line-height: 1.7;">
          <p style="margin-bottom: 1rem;">We introduce <strong style="font-weight: 600;">Aha</strong>, a high-performance open-source diffusion large language model (DLLM), alongside an open-source post-training framework specifically designed for efficient and scalable DLLM adaptation. Our framework supports long-context post-training up to 8K tokens, dramatically reducing computational cost while preserving model stability and convergence.</p>
          <p>Built upon this framework, Aha achieves state-of-the-art (SOTA) results across multiple mathematical and reasoning benchmarks, surpassing existing post-training approaches in both efficiency and generalization. This release establishes a practical, fully open foundation for advancing long-context DLLM post-training and adaptation research.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End TL;DR -->




<!-- Teaser trace-->
<section class="hero teaser" style="padding: 3rem 5rem;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <style>
        :root {
            --fg: #111;
            --bg: #fafafa;
            --muted: #888;
            --new: #0a7f2e;
            --mask: #aaa;
            --border: #ddd;
            --prompt-bg: #f5f9ff;
            --output-bg: #fdfdfd;
            --prompt-border: #a3c4f3;
            --output-border: #c4e3c4;
        }
        body {
            font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
            margin: 20px auto;
            max-width: 900px;
            color: var(--fg);
            background: var(--bg);
        }
        h1 {
            font-size: 20px;
            margin: 0 0 12px 0;
            font-weight: 600;
            text-align: center;
            color: #333;
        }
        #meta {
            color: var(--muted);
            font-size: 13px;
            margin-bottom: 10px;
            text-align: center;
        }
        .section {
            border-radius: 12px;
            padding: 16px;
            margin-bottom: 20px;
            white-space: pre-wrap;
            overflow-wrap: anywhere;
            line-height: 1.55;
            box-shadow: 0 1px 2px rgba(0,0,0,0.05);
            width: 100%;
            box-sizing: border-box;
        }
        #prompt {
            background: var(--prompt-bg);
            border: 1px solid var(--prompt-border);
            min-height: 80px;
            padding: 16px 16px !important;
        }
        #output {
            background: var(--output-bg);
            border: 1px solid var(--output-border);
            min-height: 600px;
            height: 600px;
            overflow-y: auto;
            padding: 16px 16px !important;
        }
        .masked {
            color: transparent;
            text-shadow: 0 0 0 var(--mask);
        }
        .unmasked {
            color: inherit;
        }
        .new {
            background: #e9f7ee;
            outline: 1px dashed #b7e1c3;
            animation: fadeIn 0.3s ease-out;
        }
        .prompt {
            color: #004b9b;
            font-weight: 600;
        }
        .special {
            color: var(--muted);
        }
        .maskToken {
            display:inline-block;
            width:9ch;
            text-align:center;
            opacity:0.6;
            white-space:nowrap;
        }
        @keyframes fadeIn {
            from { background:#cdecd8; }
            to { background:#e9f7ee; }
        }
        </style>

        <body>
        <h1>üß© Token Generation Trace Viewer</h1>
        <div id="meta"></div>
        
        <div id="prompt" class="section"></div>
        <div id="output" class="section"></div>

        <script id="data" type="application/json">{"pieces": ["Prompt", ":", " Given", " a", " rational", " number", ",", " write", " it", " as", " a", " fraction", " in", " lowest", " terms", " and", " calculate", " the", " product", " of", " the", " resulting", " numerator", " and", " denominator", ".", " For", " how", " many", " rational", " numbers", " between", " ", "0", " and", " ", "1", " will", " $", "2", "0", "_", "{}", "^", "{}", "!", "$", " be", " the", " resulting", " product", "?\n", "\n", "Solution", ":", " Let", " the", " rational", " number", " between", " ", "0", " and", " ", "1", " be", " $", "r", "$.", " When", " written", " as", " a", " fraction", " in", " lowest", " terms", ",", " let", " it", " be", " $", "\f", "rac", "{", "a", "}{", "b", "}$", ",", " where", " $", "a", "$", " and", " $", "b", "$", " are", " positive", " integers", ",", " $\\", "gcd", "(a", ",", " b", ")", " =", " ", "1", "$,", " and", " $", "0", " <", " a", " <", " b", "$.", " We", " are", " given", " that", " the", " product", " of", " the", " numerator", " and", " denominator", " is", " $", "2", "0", "!", "$,", " so", " $", "a", " ", "\t", "imes", " b", " =", " ", "2", "0", "!", "$.", " ", " We", " need", " to", " find", " the", " number", " of", " pairs", " $(", "a", ",", " b", ")$", " such", " that", " $", "a", " ", "\t", "imes", " b", " =", " ", "2", "0", "!", "$,", " $\\", "gcd", "(a", ",", " b", ")", " =", " ", "1", "$,", " and", " $", "a", " <", " b", "$.", " ", " Let", " $", "N", " =", " ", "2", "0", "!", "$.", " The", " prime", " factor", "ization", " of", " $", "N", "$", " is", " $", "p", "_", "1", "^{", "e", "_", "1", "}", " p", "_", "2", "^{", "e", "_", "2", "}", " \\", "cd", "ots", " p", "_k", "^{", "e", "_k", "}$", ",", " where", " $", "p", "_i", "$", " are", " distinct", " prime", " numbers", ".", " The", " number", " of", " distinct", " prime", " factors", " of", " $", "2", "0", "!", "$", " is", " the", " number", " of", " primes", " less", " than", " or", " equal", " to", " ", "2", "0", ".", " These", " primes", " are", " ", "2", ",", " ", "3", ",", " ", "5", ",", " ", "7", ",", " ", "1", "1", ",", " ", "1", "3", ",", " ", "1", "7", ",", " ", "1", "9", ".", " Thus", ",", " there", " are", " ", "8", " distinct", " prime", " factors", ",", " so", " $", "k", " =", " ", "8", "$.", " ", " Since", " $", "a", " ", "\t", "imes", " b", " =", " N", "$", " and", " $\\", "gcd", "(a", ",", " b", ")", " =", " ", "1", "$,", " each", " prime", " power", " factor", " $", "p", "_i", "^{", "e", "_i", "}$", " of", " $", "N", "$", " must", " be", " entirely", " a", " factor", " of", " $", "a", "$", " or", " entirely", " a", " factor", " of", " $", "b", "$.", " The", " number", " of", " ways", " to", " distribute", " the", " prime", " power", " factors", " between", " $", "a", "$", " and", " $", "b", "$", " is", " $", "2", "^", "k", "$,", " where", " $", "k", "$", " is", " the", " number", " of", " distinct", " prime", " factors", " of", " $", "N", "$.", " Each", " distribution", " corresponds", " to", " a", " unique", " pair", " $(", "a", ",", " b", ")$", " such", " that", " $", "a", " ", "\t", "imes", " b", " =", " N", "$", " and", " $\\", "gcd", "(a", ",", " b", ")", " =", " ", "1", "$.", " The", " number", " of", " such", " pairs", " is", " $", "2", "^", "{\\", "omega", "(N", ")}", "$,", " where", " $\\", "omega", "(N", ")$", " is", " the", " number", " of", " distinct", " prime", " factors", " of", " $", "N", "$.", " ", " Since", " $", "2", "0", "!", "$", " is", " not", " a", " perfect", " square", ",", " for", " every", " pair", " $(", "a", ",", " b", ")$", " such", " that", " $", "a", " ", "\t", "imes", " b", " =", " ", "2", "0", "!", "$", " and", " $\\", "gcd", "(a", ",", " b", ")", " =", " ", "1", "$,", " we", " have", " $", "a", " \n", "eq", " b", "$.", " The", " pairs", " can", " be", " grouped", " into", " $(", "a", ",", " b", ")$", " and", " $(", "b", ",", " a", ")$", ",", " where", " $", "a", " \n", "eq", " b", "$.", " The", " number", " of", " pairs", " with", " $", "a", " <", " b", "$", " is", " equal", " to", " the", " number", " of", " pairs", " with", " $", "b", " <", " a", "$.", " The", " total", " number", " of", " pairs", " is", " $", "2", "^", "{\\", "omega", "(", "2", "0", "!", ")}", "$.", " The", " number", " of", " pairs", " with", " $", "a", " <", " b", "$", " is", " $", "\f", "rac", "{", "1", "}{", "2", "}", " ", "\t", "imes", " ", "2", "^", "{\\", "omega", "(", "2", "0", "!", ")}", " =", " ", "2", "^", "{\\", "omega", "(", "2", "0", "!)", " -", " ", "1", "}", "$.", " ", " The", " number", " of", " distinct", " prime", " factors", " of", " $", "2", "0", "!", "$", " is", " $\\", "omega", "(", "2", "0", "!)", " =", " ", "8", "$.", " The", " number", " of", " pairs", " $(", "a", ",", " b", ")$", " such", " that", " $", "a", " ", "\t", "imes", " b", " =", " ", "2", "0", "!", "$,", " $\\", "gcd", "(a", ",", " b", ")", " =", " ", "1", "$,", " and", " $", "a", " <", " b", "$", " is", " $", "2", "^{", "8", " -", " ", "1", "}", " =", " ", "2", "^", "7", " =", " ", "1", "2", "8", "$.", " ", " Each", " such", " pair", " $(", "a", ",", " b", ")$", " corresponds", " to", " a", " unique", " rational", " number", " $", "\f", "rac", "{", "a", "}{", "b", "}$", " between", " ", "0", " and", " ", "1", " in", " lowest", " terms", ",", " with", " the", " product", " of", " the", " numerator", " and", " denominator", " equal", " to", " $", "2", "0", "!", "$.", " ", " Final", " Answer", ":", " The", " final", " answer", " is", " $", "\b", "ox", "ed", "{", "1", "2", "8", "}", "$\n"], "step_map": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743], "is_special": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "prompt_length": 52}</script>
        <script>
            const DATA = JSON.parse(document.getElementById('data').textContent);
            const pieces = DATA.pieces.map(piece => 
            piece.replace(/\f/g, '\\f').replace(/\t/g, '\\t')
                .replace(/\r/g, '\\r').replace(/\v/g, '\\v')
            );
            const steps  = DATA.step_map;
            const isSpec = DATA.is_special;
            const promptLength = DATA.prompt_length;

            const maxStep = Math.max(...steps);
            const promptEl = document.getElementById('prompt');
            const outputEl = document.getElementById('output');
            const meta = document.getElementById('meta');
            let currentStep = 0;

            function render(t) {
            const fragPrompt = document.createDocumentFragment();
            const fragOutput = document.createDocumentFragment();

            let revealed = 0;

            for (let i = 0; i < pieces.length; i++) {
                const span = document.createElement('span');
                const piece = pieces[i];
                const step = steps[i];

                if (step === -1) {
                // Prompt tokens
                span.className = 'unmasked prompt';
                span.textContent = piece;
                fragPrompt.appendChild(span);
                } else if (step <= t) {
                // Output tokens already revealed
                revealed++;
                span.className = 'unmasked' + (step === t ? ' new' : '');
                span.textContent = piece;
                fragOutput.appendChild(span);
                } else {
                // Masked or hidden tokens
                const tokenIndex = step;
                const blockStart = Math.floor(t / 4) * 4;
                const blockEnd = blockStart + 4;
                if (tokenIndex >= blockStart && tokenIndex < blockEnd) {
                    span.className = 'masked maskToken' + (isSpec[i] ? ' special' : '');
                    span.textContent = '|<MASK>|';
                    fragOutput.appendChild(span);
                }
                }
            }

            promptEl.innerHTML = '';
            promptEl.appendChild(fragPrompt);
            outputEl.innerHTML = '';
            outputEl.appendChild(fragOutput);
            // revealed ÊòØÂ∑≤Êè≠Á§∫ÁöÑËæìÂá∫ token Êï∞Èáè,t ÊòØÂΩìÂâçÊ≠•Êï∞(‰ªé0ÂºÄÂßã)
            // ÊØèÊ≠•ÁîüÊàêÁöÑ token Êï∞ = revealed / (t + 1)
            meta.textContent = `Generation speed: ${(t >= 0 ? (revealed / (t + 1)).toFixed(2) : 0)} tokens/step`;
            }

            function autoPlay() {
            render(currentStep);
            currentStep++;
            if (currentStep > maxStep) {
                setTimeout(() => {
                currentStep = 0;
                autoPlay();
                }, 2000);
            } else {
                setTimeout(autoPlay, 100);
            }
            }
            autoPlay();
        </script>
        </body>
    </div>
  </div>
</section>



<!-- HighLights Section -->
<section class="hero is-small is-light" style="padding: 5rem 1.5rem;">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered" style="margin-bottom: 0.5rem; font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;">HighLights</h2>
    <div class="content" style="font-size: 1.2rem; font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; line-height: 1.7;">
      <ul style="line-height: 1.8; margin-bottom: 0; list-style-position: outside; padding-left: 1.5rem;">
        <li style="margin-bottom: 0.75rem;"><strong style="font-weight: 600;">üöÄ Training ‚Äî Efficient Post-Training Framework:</strong> An open-source post-training framework specifically designed for DLLMs.</li>
        <li style="margin-bottom: 0.75rem;"><strong style="font-weight: 600;">‚ö° Speed ‚Äî Parallel Decoding:</strong> Up to 32√ó speedup in inference time.</li>
        <li><strong style="font-weight: 600;">üß† Performance ‚Äî Advanced Science Reasoning Benchmarks:</strong> High scores on MATH and AIME.</li>
      </ul>
    </div>
  </div>
</section>
<!-- End HighLights Section -->


<!-- Method Section -->
<section class="hero is-small" style="padding: 5rem 1.5rem;">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered" style="font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;">
      Method
    </h2>

    <div class="content has-text-justified" style="margin-bottom: 2rem; font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; font-size: 1.05rem; line-height: 1.7; color: #333;">
      <p style="margin-bottom: 1.5rem;">
        <strong style="font-weight: 600;">Aha-Math-8B-Instruct</strong> is developed based on <strong>SDAR-8B-Chat</strong> as the base model, and trained within our open-source <strong>diffusion post-training framework</strong> consisting of two stages: 
        <em>Supervised Fine-Tuning (SFT)</em> and <em>Reinforcement Learning (RL)</em>.
      </p>

      <div style="margin-bottom: 1.5rem; padding-left: 1rem; border-left: 3px solid #3273dc;">
        <h3 style="font-size: 1.15rem; font-weight: 600; margin-bottom: 0.75rem; color: #3273dc;">
          Stage 1: Supervised Fine-Tuning (SFT)
        </h3>
        <p style="margin-bottom: 0;">
          We fine-tune the model with a generation length of <strong>2K</strong>, using a high-quality dataset of <strong>2K samples synthesized by Qwen3-Max</strong>. 
          The data are carefully filtered to ensure diversity, correctness, and sequence-length consistency with training requirements.
        </p>
      </div>

      <div style="margin-bottom: 1.5rem; padding-left: 1rem; border-left: 3px solid #48c774;">
        <h3 style="font-size: 1.15rem; font-weight: 600; margin-bottom: 0.75rem; color: #48c774;">
          Stage 2: Reinforcement Learning (RL)
        </h3>
        <p style="margin-bottom: 0;">
          We adopt the <strong>Trace-RL</strong> algorithm to optimize reasoning robustness and long-context performance. 
          The generation length is extended to <strong>8K</strong>, and we integrate a <strong>diffusion-generated step map</strong> during optimization to accelerate convergence and stabilize gradient updates.
        </p>
      </div>

      <p>
        This two-stage design enables <strong>Aha-Math-8B-Instruct</strong> to achieve efficient long-context adaptation while preserving stability and strong generalization across mathematical reasoning benchmarks.
      </p>
    </div>
  </div>
</section>


<!-- Performance Section -->
<section class="hero is-small is-light" style="padding: 5rem 1.5rem;">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;">Performance</h2>

      <div class="content-has-text-justified" style="margin-bottom: 2rem; font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; font-size: 1.05rem; line-height: 1.7;">
        <p style="margin-bottom: 1rem;">
          Compared with existing instruction-tuned mathematical models, <strong style="font-weight: 600;">Aha-Math-8B-Instruct</strong> demonstrates remarkable and consistent performance gains across all evaluated benchmarks. 
          On <em>MATH500</em>, our model achieves <strong style="font-weight: 600;">82.37</strong>, outperforming the previous best (<em>Trado-8B-Instruct</em>) by <strong style="font-weight: 600;">+6.78</strong> points. 
          On <em>GSM8K</em>, it improves accuracy by <strong style="font-weight: 600;">+2.94</strong> (94.00 vs. 91.06). 
          For the more challenging <em>AIME2024</em> and <em>AIME2025</em> competitions, <strong style="font-weight: 600;">Aha-Math-8B-Instruct</strong> yields gains of <strong style="font-weight: 600;">+5.33</strong> and <strong style="font-weight: 600;">+1.00</strong> points, respectively, indicating stronger generalization to advanced and unseen mathematical problems.
        </p>
        <p>
          These results demonstrate that our post-training framework substantially enhances mathematical reasoning and generalization performance.
        </p>
      </div>
      <style>
        /* ‰∏âÁ∫øË°®Ê†∑ÂºèÔºàÈÄÇÈÖç BulmaÔºâ */
        .three-line-table {
          border-collapse: collapse;
          width: 100%;
          font-family: "Helvetica Neue", Arial, sans-serif;
          font-size: 0.95rem;
          text-align: center;
        }
        .three-line-table th,
        .three-line-table td {
          padding: 0.55rem 0.8rem;
        }

        /* È°∂Á∫øÔºàÁ≤óÔºâ*/
        .three-line-table thead tr th {
          border-top: 2px solid #0a0a0a;
        }
        /* ‰∏≠Á∫øÔºàËæÉÁªÜÔºâ*/
        .three-line-table thead {
          border-bottom: 1px solid #0a0a0a;
        }
        /* Â∫ïÁ∫øÔºàÁ≤óÔºâ*/
        .three-line-table tbody tr:last-child td {
          border-bottom: 2px solid #0a0a0a;
        }

        /* ÂéªÊéâÁ´ñÁ∫øÊïàÊûú ‚Äî‚Äî Âè™‰øùÁïô‰∏âÊù°Ê®™Á∫øÔºàÈªòËÆ§Ê≤°ÊúâÁ´ñÁ∫øÔºâ */
        .three-line-table th,
        .three-line-table td {
          border-left: none;
          border-right: none;
        }

        /* Â∞èÂØπÈΩê‰∏éÂ≠ó‰ΩìÊ†∑Âºè */
        .three-line-table thead th {
          font-weight: 600;
          padding-top: 0.9rem;
          padding-bottom: 0.6rem;
        }
        .three-line-table tbody td {
          color: #222;
        }

        /* È´ò‰∫Æ ours Ë°åÔºåÂπ∂Âä†Á≤óÂÖ∂ÊúÄ‰Ω≥ÂÄº */
        .three-line-table .ours {
          background: rgba(90,160,80,0.06);
        }
        .three-line-table .best {
          font-weight: 700;
        }

        /* ÂìçÂ∫îÂºèÔºöÂ∞èÂ±èÂπïÂ≠ó‰ΩìÂæÆË∞É */
        @media (max-width: 640px) {
          .three-line-table th, .three-line-table td { padding: 0.45rem 0.4rem; font-size: 0.88rem; }
        }
      </style>

      <div class="table-wrapper" style="margin-top:1rem;">
        <table class="three-line-table">
          <thead>
            <tr>
              <th>Model</th>
              <th>MATH500</th>
              <th>GSM8K</th>
              <th>AIME2024</th>
              <th>AIME2025</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Qwen2.5-Math-7B-Instruct</td>
              <td>75.10</td>
              <td>89.90</td>
              <td>16.67</td>
              <td>0.00</td>
            </tr>
            <tr>
              <td>SDAR-8B-Chat</td>
              <td>71.85</td>
              <td>89.87</td>
              <td>9.17</td>
              <td>9.38</td>
            </tr>
            <tr>
              <td>Trado-8B-Instruct</td>
              <td>75.59</td>
              <td>91.06</td>
              <td>11.67</td>
              <td>15.00</td>
            </tr>
            <tr class="ours">
              <td><strong>Aha-Math-8B-Instruct (ours)</strong></td>
              <td class="best">82.37</td>
              <td class="best">94.00</td>
              <td class="best">17.00</td>
              <td class="best">16.00</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </div>
</section>
<!-- End Performance Section -->
